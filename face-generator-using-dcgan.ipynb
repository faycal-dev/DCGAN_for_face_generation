{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Reshape, Dropout, Dense \nfrom tensorflow.keras.layers import Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Activation, ZeroPadding2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nimport cv2\nfrom tqdm import tqdm\nfrom glob import glob\nimport os \nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-23T23:49:28.290441Z","iopub.execute_input":"2021-10-23T23:49:28.291413Z","iopub.status.idle":"2021-10-23T23:49:34.500859Z","shell.execute_reply.started":"2021-10-23T23:49:28.291355Z","shell.execute_reply":"2021-10-23T23:49:34.499778Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<h3>the images must be a square images with 3 channels</h3>","metadata":{}},{"cell_type":"code","source":"GENERATE_SQUARE = 128\nIMAGE_CHANNELS = 3\n# Size of the vector to generate images from\nSEED_SIZE = 128","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:49:34.502775Z","iopub.execute_input":"2021-10-23T23:49:34.503161Z","iopub.status.idle":"2021-10-23T23:49:34.512698Z","shell.execute_reply.started":"2021-10-23T23:49:34.503118Z","shell.execute_reply":"2021-10-23T23:49:34.511217Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# this way we can get the path to all the images\nimages_dir =  \"../input/faces-data-new/images/\"\nimages = glob(images_dir+'*.jpg')\nimages[:5]","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:49:34.515644Z","iopub.execute_input":"2021-10-23T23:49:34.515906Z","iopub.status.idle":"2021-10-23T23:49:34.715056Z","shell.execute_reply.started":"2021-10-23T23:49:34.515863Z","shell.execute_reply":"2021-10-23T23:49:34.714075Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"<h3>here we need to read all the images with opencv and the reshape them to a square (96,96,3) and normelise them in the range [0,1] to use the sigmoid activation (we can also normelize between -1 and 1 and use tanh</h3>","metadata":{}},{"cell_type":"code","source":"training_data = []\nfor file in tqdm(images):\n    image = cv2.imread(file)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, (128,128))\n    training_data.append(image)\n# here we normelize\ntraining_data = np.array(training_data).astype(np.float32)\ntraining_data = training_data / 255","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:49:34.717481Z","iopub.execute_input":"2021-10-23T23:49:34.718090Z","iopub.status.idle":"2021-10-23T23:50:04.827218Z","shell.execute_reply.started":"2021-10-23T23:49:34.718038Z","shell.execute_reply":"2021-10-23T23:50:04.826295Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"training_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:50:19.988466Z","iopub.execute_input":"2021-10-23T23:50:19.988778Z","iopub.status.idle":"2021-10-23T23:50:19.997188Z","shell.execute_reply.started":"2021-10-23T23:50:19.988748Z","shell.execute_reply":"2021-10-23T23:50:19.996122Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Batch and shuffle the data this is a better way to use large datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices(training_data).shuffle(5000).batch(128)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:50:33.289891Z","iopub.execute_input":"2021-10-23T23:50:33.290183Z","iopub.status.idle":"2021-10-23T23:50:36.176657Z","shell.execute_reply.started":"2021-10-23T23:50:33.290152Z","shell.execute_reply":"2021-10-23T23:50:36.175646Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<h3>the gan architecture is consisted basically from 2 model generator that generates random images based on a randm seed vector and descriminator that predict if the image is real or generated we train them in an adversial way one by one so they can get better alongside and performe better because each model is trying to beat the other </h3>","metadata":{}},{"cell_type":"code","source":"# most of the hyper params are taken from the dcgan paper\n\ndef build_generator(seed_size):\n    model = Sequential()\n\n    model.add(Dense(4096, activation=\"relu\", input_dim=seed_size))\n    model.add(Reshape((4,4,256)))\n    # output shape 4,4,256\n    model.add(Conv2DTranspose(256, kernel_size=(3,3), strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    # output shape 8,8,256\n    model.add(Conv2DTranspose(256, kernel_size=(3,3), strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    # output shape 16,16,256\n    model.add(Conv2DTranspose(128, kernel_size=(3,3), strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    # output shape 32,32,128\n    model.add(Conv2DTranspose(128, kernel_size=(3,3), strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    # output shape 64,64,128\n    model.add(Conv2DTranspose(128, kernel_size=(3,3), strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    # output shape 128,128,128\n    \n    # Final CNN layer\n    model.add(Conv2D(3, kernel_size=(3,3), padding=\"same\"))\n    model.add(Activation(\"sigmoid\"))\n    # output shape 128,128,3\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:50:39.729338Z","iopub.execute_input":"2021-10-23T23:50:39.729639Z","iopub.status.idle":"2021-10-23T23:50:39.743741Z","shell.execute_reply.started":"2021-10-23T23:50:39.729608Z","shell.execute_reply":"2021-10-23T23:50:39.742569Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def build_discriminator(image_shape):\n    model = Sequential()\n\n    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    \n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:50:40.400214Z","iopub.execute_input":"2021-10-23T23:50:40.401184Z","iopub.status.idle":"2021-10-23T23:50:40.414041Z","shell.execute_reply.started":"2021-10-23T23:50:40.401137Z","shell.execute_reply":"2021-10-23T23:50:40.412888Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"generator = build_generator(SEED_SIZE)\n\nseed = tf.random.normal([1, SEED_SIZE])\ngenerated_image = generator(seed, training=False)\n\nplt.imshow(generated_image[0, :, :, 0])","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:50:52.930956Z","iopub.execute_input":"2021-10-23T23:50:52.931270Z","iopub.status.idle":"2021-10-23T23:50:53.796246Z","shell.execute_reply.started":"2021-10-23T23:50:52.931224Z","shell.execute_reply":"2021-10-23T23:50:53.795044Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"<h3>here both the generation and the decrimination are really bad because they are not trained yet</h3>","metadata":{}},{"cell_type":"code","source":"image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\n\ndiscriminator = build_discriminator(image_shape)\ndecision = discriminator(generated_image)\nprint (decision)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:50:55.809643Z","iopub.execute_input":"2021-10-23T23:50:55.810003Z","iopub.status.idle":"2021-10-23T23:50:56.016263Z","shell.execute_reply.started":"2021-10-23T23:50:55.809953Z","shell.execute_reply":"2021-10-23T23:50:56.014155Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# here we define 2 functions to calculate the loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy()\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:51:54.848530Z","iopub.execute_input":"2021-10-23T23:51:54.848885Z","iopub.status.idle":"2021-10-23T23:51:54.858620Z","shell.execute_reply.started":"2021-10-23T23:51:54.848821Z","shell.execute_reply":"2021-10-23T23:51:54.857564Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(0.0001,0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(0.0001,0.5)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:51:59.249399Z","iopub.execute_input":"2021-10-23T23:51:59.249709Z","iopub.status.idle":"2021-10-23T23:51:59.256311Z","shell.execute_reply.started":"2021-10-23T23:51:59.249676Z","shell.execute_reply":"2021-10-23T23:51:59.254730Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# this is the way to train both of the models in a generative they must never train at the same time\n@tf.function\ndef train_step(images):\n    seed = tf.random.normal([128, SEED_SIZE])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(seed, training=True)\n\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n\n        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    return gen_loss, disc_loss","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:53:12.341728Z","iopub.execute_input":"2021-10-23T23:53:12.342403Z","iopub.status.idle":"2021-10-23T23:53:12.352301Z","shell.execute_reply.started":"2021-10-23T23:53:12.342366Z","shell.execute_reply":"2021-10-23T23:53:12.350630Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train(dataset, epochs):\n    fixed_seed = np.random.normal(0, 1, (128 * 128, SEED_SIZE))\n    \n    for epoch in range(epochs):\n        gen_loss_list = []\n        disc_loss_list = []\n\n        for image_batch in dataset:\n            t = train_step(image_batch)\n            gen_loss_list.append(t[0])\n            disc_loss_list.append(t[1])\n\n        g_loss = sum(gen_loss_list) / len(gen_loss_list)\n        d_loss = sum(disc_loss_list) / len(disc_loss_list)\n\n        print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss}')","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:53:15.328773Z","iopub.execute_input":"2021-10-23T23:53:15.329566Z","iopub.status.idle":"2021-10-23T23:53:15.337327Z","shell.execute_reply.started":"2021-10-23T23:53:15.329531Z","shell.execute_reply":"2021-10-23T23:53:15.336041Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train(train_dataset, 300)","metadata":{"execution":{"iopub.status.busy":"2021-10-23T23:53:35.256360Z","iopub.execute_input":"2021-10-23T23:53:35.257326Z","iopub.status.idle":"2021-10-24T00:49:21.721148Z","shell.execute_reply.started":"2021-10-23T23:53:35.257269Z","shell.execute_reply":"2021-10-24T00:49:21.719800Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"<h3>here we train the model in adversial way </h3>","metadata":{}},{"cell_type":"code","source":"test = tf.random.normal([1, SEED_SIZE])\ngenerated_image = generator(test)\n\nplt.imshow(generated_image[0])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T00:51:30.348485Z","iopub.execute_input":"2021-10-24T00:51:30.349003Z","iopub.status.idle":"2021-10-24T00:51:30.666768Z","shell.execute_reply.started":"2021-10-24T00:51:30.348967Z","shell.execute_reply":"2021-10-24T00:51:30.665724Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"generator.save(\"face_generator.h5\")\ngenerator.save_weights(\"face_generator.weights.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-10-24T00:50:47.870389Z","iopub.execute_input":"2021-10-24T00:50:47.870766Z","iopub.status.idle":"2021-10-24T00:50:47.999592Z","shell.execute_reply.started":"2021-10-24T00:50:47.870698Z","shell.execute_reply":"2021-10-24T00:50:47.998530Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}